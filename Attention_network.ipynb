{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/c1501f/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras import activations\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import optimizers\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras import utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "KTF.set_session(session )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_processing(data):\n",
    "    \n",
    "    data_mean = data.mean()\n",
    "    data_var = data.var()\n",
    "    \n",
    "    data = data - data_mean\n",
    "    data = data / data_var\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = 196\n",
    "test_batch = 196\n",
    "\n",
    "train_num = 142420\n",
    "test_num = 45668\n",
    "\n",
    "cross = \"cross_1\"\n",
    "\n",
    "snr_str = \"-6_detail_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_1d_train_data():\n",
    "    \n",
    "    train_data = np.zeros((train_batch, 2048, 1), dtype = np.float32)\n",
    "\n",
    "    \n",
    "    train_lab = np.zeros((train_batch))\n",
    "    flag = 0\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        list = random.sample(range(train_num), train_num)\n",
    "        \n",
    "        for id in list:\n",
    "            \n",
    "            num_id = str(id)\n",
    "            \n",
    "            line_train_data = np.load(\"../../H-S_data/noise_data/\"+cross+\"/\"+snr_str+\"/train_data/\" + num_id + \"_train.npy\")\n",
    "            line_train_lab = np.load(\"../../H-S_data/noise_data/\"+cross+\"/\"+snr_str+\"/train_lab/\" + num_id + \"_lab.npy\")\n",
    "            \n",
    "            line_train_data = normalization_processing(line_train_data)\n",
    "\n",
    "            train_data[flag , :, 0] = line_train_data\n",
    "\n",
    "            train_lab[flag] = line_train_lab\n",
    "            \n",
    "            flag += 1\n",
    "            \n",
    "            if flag >= train_batch:\n",
    "                \n",
    "                train_hot_lab = to_categorical(train_lab, num_classes=12)\n",
    "                \n",
    "                yield [train_data], [train_hot_lab]\n",
    "                \n",
    "                flag = 0\n",
    "                train_data = np.zeros((train_batch, 2048, 1), dtype = np.float32)\n",
    "                \n",
    "                train_lab = np.zeros((train_batch))\n",
    "\n",
    "        \n",
    "def generate_1d_test_data():\n",
    "    \n",
    "    test_data = np.zeros((test_batch, 2048, 1), dtype = np.float32)\n",
    "    \n",
    "    test_lab = np.zeros((test_batch))\n",
    "    flag = 0\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        list = random.sample(range(test_num), test_num)\n",
    "        \n",
    "        for id in list:\n",
    "            \n",
    "            num_id = str(id)\n",
    "            \n",
    "            line_test_data = np.load(\"../../H-S_data/noise_data/\"+cross+\"/\"+snr_str+\"/test_data/\" + num_id + \"_test.npy\")\n",
    "            line_test_lab = np.load(\"../../H-S_data/noise_data/\"+cross+\"/\"+snr_str+\"/test_lab/\" + num_id + \"_lab.npy\")\n",
    "            \n",
    "            line_test_data = normalization_processing(line_test_data)\n",
    "            \n",
    "            test_data[flag , :, 0] = line_test_data\n",
    "            \n",
    "            test_lab[flag] = line_test_lab\n",
    "            \n",
    "            flag += 1\n",
    "            \n",
    "            if flag >= train_batch:\n",
    "                \n",
    "                test_hot_lab = to_categorical(test_lab, num_classes=12)\n",
    "                \n",
    "                yield [test_data], [test_hot_lab]\n",
    "                \n",
    "                flag = 0\n",
    "                test_data = np.zeros((test_batch, 2048, 1), dtype = np.float32)\n",
    "          \n",
    "                test_lab = np.zeros((test_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_test_data():\n",
    "    \n",
    "    test_data = np.zeros((test_num, 2048, 1), dtype = np.float32)\n",
    "    \n",
    "    test_lab = np.zeros((test_num))\n",
    "    \n",
    "    flag = 0\n",
    "    list = random.sample(range(test_num), test_num)\n",
    "    \n",
    "    for id in list:\n",
    "        \n",
    "        num_id = str(id)\n",
    "        \n",
    "        line_test_data = np.load(\"../../H-S_data/noise_data/\"+cross+\"/\"+snr_str+\"/test_data/\" + num_id + \"_test.npy\")\n",
    "        line_test_lab = np.load(\"../../H-S_data/noise_data/\"+cross+\"/\"+snr_str+\"/test_lab/\" + num_id + \"_lab.npy\")\n",
    "        \n",
    "        line_test_data = normalization_processing(line_test_data)\n",
    "\n",
    "        test_data[flag , :, 0] = line_test_data\n",
    "        \n",
    "        test_lab[flag] = line_test_lab\n",
    "        \n",
    "        flag += 1\n",
    "        \n",
    "    test_hot_lab = to_categorical(test_lab, num_classes=12)\n",
    "    \n",
    "    return test_data, test_hot_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1D_bn(x, filters, kernel_size, strides):\n",
    "    \n",
    "    C1 = Conv1D(filters, kernel_size, strides=strides, padding='same')(x) \n",
    "    C1 = Activation('relu')(C1)\n",
    "    \n",
    "    return C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_CAM(in_x, nb_filter):\n",
    "\n",
    "    c = GlobalAveragePooling1D()(in_x)\n",
    "    c = Reshape((1, nb_filter))(c)\n",
    "    \n",
    "    c = Conv1D(int(nb_filter/2), 1, padding='same')(c) \n",
    "    #c = BatchNormalization()(c)\n",
    "    c = Activation('relu')(c)\n",
    "    \n",
    "    c = Conv1D(nb_filter, 1, padding='same')(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    c = Activation('sigmoid')(c)\n",
    "    \n",
    "    x = multiply([in_x, c])\n",
    "    out = add([in_x, x])\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "def A_EAM(in_x, nb_filter, kernel_size):\n",
    "        \n",
    "    t = Conv1D(1, 1, padding='same')(in_x)\n",
    "    t = BatchNormalization()(t)\n",
    "    t = Activation('sigmoid')(t)\n",
    "    \n",
    "    x = Conv1D(nb_filter, kernel_size, padding='same')(in_x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = multiply([x, t])\n",
    "    out = add([in_x, x])\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "def A_JAM(in_x, nb_filter, kernel_size):\n",
    "    \n",
    "    cx = A_CAM(in_x, nb_filter)\n",
    "    tx = A_tSE(cx, nb_filter, kernel_size)\n",
    "    \n",
    "    return tx   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MA1DCNN():\n",
    "    \n",
    "    input_signal = Input(shape=(2048,1))\n",
    "\n",
    "    cnn = Conv1D(32, kernel_size = 32, activation='relu', padding='same', strides=1)(input_signal)\n",
    "    cnn = A_EAM(cnn, 32, 32)\n",
    "    cnn = A_CAM(cnn, 32)\n",
    "\n",
    "    cnn = Conv1D(32, kernel_size = 16, activation='relu', padding='same', strides=2)(cnn)   \n",
    "    cnn = A_EAM(cnn, 32, 16)\n",
    "    cnn = A_CAM(cnn, 32)\n",
    "\n",
    "    cnn = Conv1D(64, kernel_size = 9, activation='relu', padding='same', strides=2)(cnn)\n",
    "    cnn = A_EAM(cnn, 64, 9)\n",
    "    cnn = A_CAM(cnn, 64)    \n",
    "\n",
    "    cnn = Conv1D(64, kernel_size = 6, activation='relu', padding='same', strides=2)(cnn)\n",
    "    cnn = A_EAM(cnn, 64, 6)\n",
    "    cnn = A_CAM(cnn, 64)\n",
    "    \n",
    "    cnn = Conv1D(128, kernel_size = 3, activation='relu', padding='same', strides=4)(cnn)\n",
    "    cnn = A_EAM(cnn, 128, 3)\n",
    "    cnn = A_CAM(cnn, 128)\n",
    "    \n",
    "    cnn = Conv1D(128, kernel_size = 3, activation='relu', padding='same', strides=4)(cnn)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(cnn)\n",
    "    \n",
    "    output = Dense(12, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_signal, outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACAM_CNN():\n",
    "    \n",
    "    input_signal = Input(shape=(2048,1))\n",
    "\n",
    "    cnn = Conv1D(32, kernel_size = 32, activation='relu', padding='same', strides=1)(input_signal)\n",
    "    cnn = A_CAM(cnn, 32)\n",
    "\n",
    "    cnn = Conv1D(32, kernel_size = 16, activation='relu', padding='same', strides=2)(cnn)   \n",
    "    cnn = A_CAM(cnn, 32)\n",
    "\n",
    "    cnn = Conv1D(64, kernel_size = 9, activation='relu', padding='same', strides=2)(cnn)\n",
    "    cnn = A_CAM(cnn, 64)\n",
    "\n",
    "    cnn = Conv1D(64, kernel_size = 6, activation='relu', padding='same', strides=2)(cnn)\n",
    "    cnn = A_CAM(cnn, 64)\n",
    "    \n",
    "    cnn = Conv1D(128, kernel_size = 3, activation='relu', padding='same', strides=4)(cnn)\n",
    "    cnn = A_CAM(cnn, 128)\n",
    "    \n",
    "    cnn = Conv1D(128, kernel_size = 3, activation='relu', padding='same', strides=4)(cnn)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(cnn)\n",
    "    \n",
    "    output = Dense(12, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_signal, outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def AEAM_CNN():\n",
    "    \n",
    "    input_signal = Input(shape=(2048,1))\n",
    "\n",
    "    cnn = Conv1D(32, kernel_size = 32, activation='relu', padding='same', strides=1)(input_signal)\n",
    "    cnn = A_EAM(cnn, 32, 32)\n",
    "\n",
    "    cnn = Conv1D(32, kernel_size = 16, activation='relu', padding='same', strides=2)(cnn)   \n",
    "    cnn = A_EAM(cnn, 32, 16)\n",
    "\n",
    "    cnn = Conv1D(64, kernel_size = 9, activation='relu', padding='same', strides=2)(cnn)\n",
    "    cnn = A_EAM(cnn, 64, 9)\n",
    "\n",
    "    cnn = Conv1D(64, kernel_size = 6, activation='relu', padding='same', strides=2)(cnn)\n",
    "    cnn = A_EAM(cnn, 64, 6)\n",
    "    \n",
    "    cnn = Conv1D(128, kernel_size = 3, activation='relu', padding='same', strides=4)(cnn)\n",
    "    cnn = A_EAM(cnn, 128, 3)\n",
    "    \n",
    "    cnn = Conv1D(128, kernel_size = 3, activation='relu', padding='same', strides=4)(cnn)\n",
    "\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(cnn)\n",
    "    \n",
    "    output = Dense(12, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_signal, outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_CNN():\n",
    "    \n",
    "    input_signal = Input(shape=(2048,1))\n",
    "\n",
    "    cnn = Conv1D(32, kernel_size = 32, activation='relu', padding='same', strides=1)(input_signal)\n",
    "\n",
    "    cnn = Conv1D(32, kernel_size = 16, activation='relu', padding='same', strides=2)(cnn)   \n",
    "\n",
    "    cnn = Conv1D(64, kernel_size = 9, activation='relu', padding='same', strides=2)(cnn)\n",
    "\n",
    "    cnn = Conv1D(64, kernel_size = 6, activation='relu', padding='same', strides=2)(cnn)\n",
    "    \n",
    "    cnn = Conv1D(128, kernel_size = 3, activation='relu', padding='same', strides=4)(cnn)\n",
    "    \n",
    "    cnn = Conv1D(128, kernel_size = 3, activation='relu', padding='same', strides=4)(cnn)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(cnn)\n",
    "    \n",
    "    output = Dense(12, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_signal, outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AJAM_WDCNN():\n",
    "    \n",
    "    input_signal = Input((2048, 1))\n",
    "    \n",
    "    x = Conv1D(16, 64, strides=16, padding='same')(input_signal)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = A_EAM(x, 16, 64)\n",
    "    x = A_CAM(x, 16)   \n",
    "    x = MaxPooling1D(2)(x)\n",
    "    \n",
    "    x = Conv1D(32, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = A_EAM(x, 32, 3)\n",
    "    x = A_CAM(x, 32)      \n",
    "    x = MaxPooling1D(2)(x)\n",
    "    \n",
    "    x = Conv1D(64, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = A_EAM(x, 64, 3)\n",
    "    x = A_CAM(x, 64)      \n",
    "    x = MaxPooling1D(2)(x)\n",
    "    \n",
    "    x = Conv1D(64, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = A_EAM(x, 64, 3)\n",
    "    x = A_CAM(x, 64)    \n",
    "    x = MaxPooling1D(2)(x)\n",
    "    \n",
    "    x = Conv1D(64, 3, padding='valid')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = MaxPooling1D(2)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    x = Dense(100,  activation='relu')(x)\n",
    "    \n",
    "    x = Dense(12,  activation='softmax')(x)\n",
    "    \n",
    "    model = Model(input_signal, x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/c1501f/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 2048, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 2048, 32)     1056        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 2048, 1)      33          conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 2048, 32)     32800       conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2048, 1)      4           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 2048, 32)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 2048, 1)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 2048, 32)     0           activation_2[0][0]               \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 2048, 32)     0           conv1d_1[0][0]                   \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 32)           0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 32)        0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1, 16)        528         reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1, 16)        0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1, 32)        544         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1, 32)        128         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1, 32)        0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 2048, 32)     0           add_1[0][0]                      \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 2048, 32)     0           add_1[0][0]                      \n",
      "                                                                 multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1024, 32)     16416       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1024, 1)      33          conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1024, 32)     16416       conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1024, 1)      4           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1024, 32)     0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 1024, 1)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 1024, 32)     0           activation_6[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 1024, 32)     0           conv1d_6[0][0]                   \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 32)           0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 32)        0           global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1, 16)        528         reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1, 16)        0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1, 32)        544         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1, 32)        128         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1, 32)        0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 1024, 32)     0           add_3[0][0]                      \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 1024, 32)     0           add_3[0][0]                      \n",
      "                                                                 multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 512, 64)      18496       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 512, 1)       65          conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 512, 64)      36928       conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 512, 1)       4           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 512, 64)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 512, 1)       0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 512, 64)      0           activation_10[0][0]              \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 512, 64)      0           conv1d_11[0][0]                  \n",
      "                                                                 multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 64)           0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 64)        0           global_average_pooling1d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1, 32)        2080        reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 1, 32)        0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 1, 64)        2112        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1, 64)        256         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 1, 64)        0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 512, 64)      0           add_5[0][0]                      \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 512, 64)      0           add_5[0][0]                      \n",
      "                                                                 multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 256, 64)      24640       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 256, 1)       65          conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 256, 64)      24640       conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256, 1)       4           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 256, 64)      0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 256, 1)       0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 256, 64)      0           activation_14[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 256, 64)      0           conv1d_16[0][0]                  \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 64)           0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 64)        0           global_average_pooling1d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 1, 32)        2080        reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 1, 32)        0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1, 64)        2112        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1, 64)        256         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 1, 64)        0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 256, 64)      0           add_7[0][0]                      \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 256, 64)      0           add_7[0][0]                      \n",
      "                                                                 multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 64, 128)      24704       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 64, 1)        129         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 64, 128)      49280       conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 1)        4           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 64, 128)      0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 64, 1)        0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 64, 128)      0           activation_18[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 64, 128)      0           conv1d_21[0][0]                  \n",
      "                                                                 multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 128)          0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1, 128)       0           global_average_pooling1d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 1, 64)        8256        reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 1, 64)        0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 1, 128)       8320        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1, 128)       512         conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 1, 128)       0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 64, 128)      0           add_9[0][0]                      \n",
      "                                                                 activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 64, 128)      0           add_9[0][0]                      \n",
      "                                                                 multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 16, 128)      49280       add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 128)          0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 12)           1548        global_average_pooling1d_6[0][0] \n",
      "==================================================================================================\n",
      "Total params: 324,933\n",
      "Trainable params: 324,283\n",
      "Non-trainable params: 650\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adam = optimizers.adam(lr = 0.0001)\n",
    "\n",
    "model = MA1DCNN()\n",
    "\n",
    "model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics = [\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "727/726 [==============================] - 234s 322ms/step - loss: 1.4719 - acc: 0.4545 - val_loss: 1.2517 - val_acc: 0.5176\n",
      "save model----model_at_epoch_0.h5\n",
      "Epoch 2/100\n",
      "727/726 [==============================] - 211s 290ms/step - loss: 1.1115 - acc: 0.5782 - val_loss: 1.0882 - val_acc: 0.6045\n",
      "save model----model_at_epoch_1.h5\n",
      "Epoch 3/100\n",
      "727/726 [==============================] - 204s 281ms/step - loss: 0.8064 - acc: 0.6995 - val_loss: 0.7498 - val_acc: 0.7236\n",
      "save model----model_at_epoch_2.h5\n",
      "Epoch 4/100\n",
      "727/726 [==============================] - 200s 276ms/step - loss: 0.5653 - acc: 0.7905 - val_loss: 0.6194 - val_acc: 0.7749\n",
      "save model----model_at_epoch_3.h5\n",
      "Epoch 5/100\n",
      "727/726 [==============================] - 200s 275ms/step - loss: 0.4281 - acc: 0.8424 - val_loss: 0.9439 - val_acc: 0.7443\n",
      "save model----model_at_epoch_4.h5\n",
      "Epoch 6/100\n",
      "727/726 [==============================] - 199s 274ms/step - loss: 0.3370 - acc: 0.8763 - val_loss: 0.6063 - val_acc: 0.7877\n",
      "save model----model_at_epoch_5.h5\n",
      "Epoch 7/100\n",
      "727/726 [==============================] - 199s 274ms/step - loss: 0.2592 - acc: 0.9051 - val_loss: 0.5715 - val_acc: 0.8134\n",
      "save model----model_at_epoch_6.h5\n",
      "Epoch 8/100\n",
      "727/726 [==============================] - 199s 273ms/step - loss: 0.2070 - acc: 0.9253 - val_loss: 1.0164 - val_acc: 0.7760\n",
      "save model----model_at_epoch_7.h5\n",
      "Epoch 9/100\n",
      "727/726 [==============================] - 198s 273ms/step - loss: 0.1583 - acc: 0.9437 - val_loss: 0.6238 - val_acc: 0.8072\n",
      "save model----model_at_epoch_8.h5\n",
      "Epoch 10/100\n",
      "727/726 [==============================] - 197s 271ms/step - loss: 0.1201 - acc: 0.9573 - val_loss: 0.7331 - val_acc: 0.8218\n",
      "save model----model_at_epoch_9.h5\n",
      "Epoch 11/100\n",
      "727/726 [==============================] - 197s 271ms/step - loss: 0.1031 - acc: 0.9636 - val_loss: 0.7939 - val_acc: 0.8110\n",
      "save model----model_at_epoch_10.h5\n",
      "Epoch 12/100\n",
      "727/726 [==============================] - 199s 273ms/step - loss: 0.0862 - acc: 0.9693 - val_loss: 0.9576 - val_acc: 0.7890\n",
      "save model----model_at_epoch_11.h5\n",
      "Epoch 13/100\n",
      "727/726 [==============================] - 198s 272ms/step - loss: 0.0609 - acc: 0.9793 - val_loss: 0.8095 - val_acc: 0.8024\n",
      "save model----model_at_epoch_12.h5\n",
      "Epoch 14/100\n",
      "727/726 [==============================] - 199s 274ms/step - loss: 0.0513 - acc: 0.9820 - val_loss: 0.9074 - val_acc: 0.8067\n",
      "save model----model_at_epoch_13.h5\n",
      "Epoch 15/100\n",
      "727/726 [==============================] - 199s 273ms/step - loss: 0.0522 - acc: 0.9822 - val_loss: 1.1679 - val_acc: 0.7958\n",
      "save model----model_at_epoch_14.h5\n",
      "Epoch 16/100\n",
      "727/726 [==============================] - 199s 274ms/step - loss: 0.0475 - acc: 0.9839 - val_loss: 1.1374 - val_acc: 0.7774\n",
      "save model----model_at_epoch_15.h5\n",
      "Epoch 17/100\n",
      "727/726 [==============================] - 199s 274ms/step - loss: 0.0461 - acc: 0.9849 - val_loss: 1.1025 - val_acc: 0.7801\n",
      "save model----model_at_epoch_16.h5\n",
      "Epoch 18/100\n",
      "727/726 [==============================] - 198s 272ms/step - loss: 0.0318 - acc: 0.9892 - val_loss: 0.9938 - val_acc: 0.8010\n",
      "save model----model_at_epoch_17.h5\n",
      "Epoch 19/100\n",
      "727/726 [==============================] - 201s 277ms/step - loss: 0.0338 - acc: 0.9889 - val_loss: 0.9896 - val_acc: 0.8196\n",
      "save model----model_at_epoch_18.h5\n",
      "Epoch 20/100\n",
      "727/726 [==============================] - 199s 274ms/step - loss: 0.0313 - acc: 0.9896 - val_loss: 0.9953 - val_acc: 0.8163\n",
      "save model----model_at_epoch_19.h5\n",
      "Epoch 21/100\n",
      "727/726 [==============================] - 202s 278ms/step - loss: 0.0303 - acc: 0.9896 - val_loss: 1.5376 - val_acc: 0.7769\n",
      "save model----model_at_epoch_20.h5\n",
      "Epoch 22/100\n",
      "727/726 [==============================] - 202s 277ms/step - loss: 0.0295 - acc: 0.9902 - val_loss: 1.0452 - val_acc: 0.8068\n",
      "save model----model_at_epoch_21.h5\n",
      "Epoch 23/100\n",
      "727/726 [==============================] - 201s 277ms/step - loss: 0.0213 - acc: 0.9930 - val_loss: 1.1183 - val_acc: 0.8133\n",
      "save model----model_at_epoch_22.h5\n",
      "Epoch 24/100\n",
      "727/726 [==============================] - 201s 276ms/step - loss: 0.0204 - acc: 0.9934 - val_loss: 1.1138 - val_acc: 0.8119\n",
      "save model----model_at_epoch_23.h5\n",
      "Epoch 25/100\n",
      "727/726 [==============================] - 202s 277ms/step - loss: 0.0246 - acc: 0.9919 - val_loss: 1.4980 - val_acc: 0.7436\n",
      "save model----model_at_epoch_24.h5\n",
      "Epoch 26/100\n",
      "727/726 [==============================] - 201s 277ms/step - loss: 0.0167 - acc: 0.9945 - val_loss: 1.0733 - val_acc: 0.8237\n",
      "save model----model_at_epoch_25.h5\n",
      "Epoch 27/100\n",
      "727/726 [==============================] - 202s 277ms/step - loss: 0.0230 - acc: 0.9925 - val_loss: 1.7709 - val_acc: 0.7626\n",
      "save model----model_at_epoch_26.h5\n",
      "Epoch 28/100\n",
      "727/726 [==============================] - 201s 277ms/step - loss: 0.0164 - acc: 0.9947 - val_loss: 1.1140 - val_acc: 0.7987\n",
      "save model----model_at_epoch_27.h5\n",
      "Epoch 29/100\n",
      "727/726 [==============================] - 203s 279ms/step - loss: 0.0169 - acc: 0.9945 - val_loss: 1.0455 - val_acc: 0.8251\n",
      "save model----model_at_epoch_28.h5\n",
      "Epoch 30/100\n",
      "727/726 [==============================] - 200s 275ms/step - loss: 0.0155 - acc: 0.9950 - val_loss: 1.0272 - val_acc: 0.8246\n",
      "save model----model_at_epoch_29.h5\n",
      "Epoch 31/100\n",
      "727/726 [==============================] - 201s 276ms/step - loss: 0.0174 - acc: 0.9944 - val_loss: 1.2372 - val_acc: 0.8069\n",
      "save model----model_at_epoch_30.h5\n",
      "Epoch 32/100\n",
      "727/726 [==============================] - 201s 277ms/step - loss: 0.0129 - acc: 0.9959 - val_loss: 1.1397 - val_acc: 0.8239\n",
      "save model----model_at_epoch_31.h5\n",
      "Epoch 33/100\n",
      "727/726 [==============================] - 200s 275ms/step - loss: 0.0113 - acc: 0.9965 - val_loss: 1.1706 - val_acc: 0.8242\n",
      "save model----model_at_epoch_32.h5\n",
      "Epoch 34/100\n",
      "610/726 [========================>.....] - ETA: 23s - loss: 0.0124 - acc: 0.9963"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-37e4d3533e4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mreduceLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcooldown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0000001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_1d_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_num\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_1d_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_num\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduceLR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class MyCbk(Callback):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model_to_save = model\n",
    "            \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        print('save model----model_at_epoch_%d.h5' % epoch)\n",
    "        self.model_to_save.save('model_1/model_%d.h5' % epoch)\n",
    "        \n",
    "cbk = MyCbk(model)\n",
    "\n",
    "reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.90, patience=5, verbose=0, mode='auto', cooldown=0, min_lr=0.0000001)\n",
    "\n",
    "results = model.fit_generator(generate_1d_train_data(), steps_per_epoch = train_num/train_batch, epochs = 100, validation_data = generate_1d_test_data(), validation_steps = test_num/test_batch, verbose=1, callbacks=[cbk, reduceLR])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_data, all_test_lab = get_all_test_data()\n",
    "\n",
    "\n",
    "Accuracy_list = np.zeros((100))\n",
    "Recall_list = np.zeros((100))\n",
    "Precision_list = np.zeros((100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/c1501f/anaconda3/envs/tensorflow/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.5175615310501883\n",
      "0.43814934298033786\n",
      "0.42098025842361114\n",
      "------------------------------------\n",
      "1\n",
      "0.6045151966365946\n",
      "0.5251392640247031\n",
      "0.5384809748004432\n",
      "------------------------------------\n",
      "2\n",
      "0.7236358062538321\n",
      "0.6767394539934148\n",
      "0.7109982213431106\n",
      "------------------------------------\n",
      "3\n",
      "0.774853288955067\n",
      "0.7409510101365298\n",
      "0.7548192288670988\n",
      "------------------------------------\n",
      "4\n",
      "0.7442629412279933\n",
      "0.6935714803170833\n",
      "0.7585717440728352\n",
      "------------------------------------\n",
      "5\n",
      "0.7877069282648682\n",
      "0.7938955901529748\n",
      "0.7950809456765522\n",
      "------------------------------------\n",
      "6\n",
      "0.8133704125426995\n",
      "0.7800017260929586\n",
      "0.8054403729826465\n",
      "------------------------------------\n",
      "7\n",
      "0.7760138390119996\n",
      "0.7438355877970539\n",
      "0.8034970307351433\n",
      "------------------------------------\n",
      "8\n",
      "0.8071735131820968\n",
      "0.8106748278363142\n",
      "0.81780615042158\n",
      "------------------------------------\n",
      "9\n",
      "0.8217570289918542\n",
      "0.7994735662691824\n",
      "0.8197602958684297\n",
      "------------------------------------\n",
      "10\n",
      "0.8110274152579486\n",
      "0.7994005104462608\n",
      "0.8011335046784295\n",
      "------------------------------------\n",
      "11\n",
      "0.789042655688885\n",
      "0.7665700383166482\n",
      "0.7877877524423753\n",
      "------------------------------------\n",
      "12\n",
      "0.8023780327581677\n",
      "0.7909451909703655\n",
      "0.7927204850186819\n",
      "------------------------------------\n",
      "13\n",
      "0.8066917754226154\n",
      "0.8066304908032552\n",
      "0.7985847173638448\n",
      "------------------------------------\n",
      "14\n",
      "0.7957650871507401\n",
      "0.749411791564047\n",
      "0.8212352532869467\n",
      "------------------------------------\n",
      "15\n",
      "0.7773933607777875\n",
      "0.7944309538437156\n",
      "0.7763251856983487\n",
      "------------------------------------\n",
      "16\n",
      "0.7800867127967067\n",
      "0.7611241847597245\n",
      "0.7623138685738864\n",
      "------------------------------------\n",
      "17\n",
      "0.8009547166506087\n",
      "0.8007854578662178\n",
      "0.791391132561253\n",
      "------------------------------------\n",
      "18\n",
      "0.8195892090741876\n",
      "0.8041607809011811\n",
      "0.8135520316045529\n",
      "------------------------------------\n",
      "19\n",
      "0.8163046334413594\n",
      "0.7975446246936916\n",
      "0.816043825771244\n",
      "------------------------------------\n",
      "20\n",
      "0.7769116230183061\n",
      "0.7446689047429178\n",
      "0.7901882593336271\n",
      "------------------------------------\n",
      "21\n",
      "0.8068231584479285\n",
      "0.8072613433901697\n",
      "0.7947478747442306\n",
      "------------------------------------\n",
      "22\n",
      "0.813348515371814\n",
      "0.7848941320233949\n",
      "0.825678194753963\n",
      "------------------------------------\n",
      "23\n",
      "0.8119251992642551\n",
      "0.8017142168869142\n",
      "0.8176320964536025\n",
      "------------------------------------\n",
      "24\n",
      "0.7435622317596566\n",
      "0.7677265141408199\n",
      "0.7526131744812444\n",
      "------------------------------------\n",
      "25\n",
      "0.8237277743715512\n",
      "0.8099392080586697\n",
      "0.8123766352238185\n",
      "------------------------------------\n",
      "26\n",
      "0.7626127704300605\n",
      "0.7247126691348295\n",
      "0.7813699130471959\n",
      "------------------------------------\n",
      "27\n",
      "0.798655513707629\n",
      "0.797116472186961\n",
      "0.7898228860172355\n",
      "------------------------------------\n",
      "28\n",
      "0.825107296137339\n",
      "0.815076816948964\n",
      "0.8170841243124934\n",
      "------------------------------------\n",
      "29\n",
      "0.8246474555487431\n",
      "0.8064965393862412\n",
      "0.8192799444116036\n",
      "------------------------------------\n",
      "30\n",
      "0.8068888499605851\n",
      "0.7993890186324397\n",
      "0.7998957444294271\n",
      "------------------------------------\n",
      "31\n",
      "0.8239467460804064\n",
      "0.7966803192853811\n",
      "0.8324572834627801\n",
      "------------------------------------\n",
      "32\n",
      "0.8241876149601471\n",
      "0.7986514287257775\n",
      "0.8245585661968852\n",
      "------------------------------------\n",
      "33\n",
      "0.7984365419987738\n",
      "0.7686403464372383\n",
      "0.8037611032524943\n",
      "------------------------------------\n",
      "34\n",
      "0.8064290093719891\n",
      "0.8017246378643733\n",
      "0.7930741768934554\n",
      "------------------------------------\n",
      "35\n",
      "0.8018743978278007\n",
      "0.7787506481526689\n",
      "0.8042508015498114\n",
      "------------------------------------\n",
      "36\n",
      "0.7913637558027503\n",
      "0.7677738646438298\n",
      "0.7942918350225011\n",
      "------------------------------------\n",
      "37\n",
      "0.7750722606639222\n",
      "0.7443774762031342\n",
      "0.7853074928065608\n",
      "------------------------------------\n",
      "38\n",
      "0.8066479810808443\n",
      "0.7746013005386327\n",
      "0.8107356036276622\n",
      "------------------------------------\n",
      "39\n",
      "0.767802399929929\n",
      "0.7742476258512442\n",
      "0.7672804817449864\n",
      "------------------------------------\n",
      "40\n",
      "0.7853858281510029\n",
      "0.7500458744198676\n",
      "0.7954127377753809\n",
      "------------------------------------\n",
      "41\n",
      "0.8166768853464133\n",
      "0.8021767528069557\n",
      "0.8100470076988718\n",
      "------------------------------------\n",
      "42\n",
      "0.7799334326005081\n",
      "0.7548798598291752\n",
      "0.7825301986191401\n",
      "------------------------------------\n",
      "43\n",
      "0.8206621704475782\n",
      "0.8016066085287687\n",
      "0.8158638306601252\n",
      "------------------------------------\n",
      "44\n",
      "0.8226767101690462\n",
      "0.8135413542553042\n",
      "0.8098361630754903\n",
      "------------------------------------\n",
      "45\n",
      "0.8064947008846457\n",
      "0.7946833051307407\n",
      "0.8031676095834334\n",
      "------------------------------------\n",
      "46\n",
      "0.8141806078654638\n",
      "0.7952540221630918\n",
      "0.8102613690970343\n",
      "------------------------------------\n",
      "47\n",
      "0.7950424805115179\n",
      "0.775765439724724\n",
      "0.7935297344892086\n",
      "------------------------------------\n",
      "48\n",
      "0.8246255583778576\n",
      "0.8091705219197499\n",
      "0.8193104640230189\n",
      "------------------------------------\n",
      "49\n",
      "0.7941009021634405\n",
      "0.7659949878884492\n",
      "0.8135853001989676\n",
      "------------------------------------\n",
      "50\n",
      "0.8152535692388544\n",
      "0.7930571365830833\n",
      "0.8121408138925911\n",
      "------------------------------------\n",
      "51\n",
      "0.7871813961636157\n",
      "0.751236224273449\n",
      "0.7943393233345258\n",
      "------------------------------------\n",
      "52\n",
      "0.8165892966628712\n",
      "0.7941681157871745\n",
      "0.8120951952194462\n",
      "------------------------------------\n",
      "53\n",
      "0.8070202329858982\n",
      "0.787368347268656\n",
      "0.8023218826209823\n",
      "------------------------------------\n",
      "54\n",
      "0.8136331785933257\n",
      "0.7908508576733267\n",
      "0.81002600225721\n",
      "------------------------------------\n",
      "55\n",
      "0.8122317596566524\n",
      "0.7891888356837001\n",
      "0.8080228649055354\n",
      "------------------------------------\n",
      "56\n",
      "0.8199176666374705\n",
      "0.807007735192315\n",
      "0.8095947180590827\n",
      "------------------------------------\n",
      "57\n",
      "0.8272313217132347\n",
      "0.8093269847146728\n",
      "0.8217101572256795\n",
      "------------------------------------\n",
      "58\n",
      "0.773758430410791\n",
      "0.7688270517822074\n",
      "0.7507679190875524\n",
      "------------------------------------\n",
      "59\n",
      "0.8136988701059823\n",
      "0.7889314163901302\n",
      "0.8143053285579315\n",
      "------------------------------------\n",
      "60\n",
      "0.8283480774283962\n",
      "0.8114314772578736\n",
      "0.8204193307862132\n",
      "------------------------------------\n",
      "61\n",
      "0.8279539283524568\n",
      "0.8103261666651167\n",
      "0.8210740835560107\n",
      "------------------------------------\n",
      "62\n",
      "0.8098011736883595\n",
      "0.7900209102494951\n",
      "0.8032826798815672\n",
      "------------------------------------\n",
      "63\n",
      "0.8206183761058071\n",
      "0.7982892034927817\n",
      "0.8184164637240995\n",
      "------------------------------------\n",
      "64\n",
      "0.7963344135937637\n",
      "0.7688486339986742\n",
      "0.7977296419086136\n",
      "------------------------------------\n",
      "65\n",
      "0.8173775948147499\n",
      "0.7936358358468322\n",
      "0.8185011062120312\n",
      "------------------------------------\n",
      "66\n",
      "0.8034947884733292\n",
      "0.7882384161418802\n",
      "0.7913376469681733\n",
      "------------------------------------\n",
      "67\n",
      "0.8144214767452045\n",
      "0.7899165261057716\n",
      "0.8167516042296961\n",
      "------------------------------------\n",
      "68\n",
      "0.8103048086187264\n",
      "0.7966073885884574\n",
      "0.8015418353448341\n",
      "------------------------------------\n",
      "69\n",
      "0.8063852150302181\n",
      "0.793482553674048\n",
      "0.7910514129469405\n",
      "------------------------------------\n",
      "70\n",
      "0.7137820793553473\n",
      "0.7552095357538094\n",
      "0.7421157078434755\n",
      "------------------------------------\n",
      "71\n",
      "0.8105237803275817\n",
      "0.7958835459926356\n",
      "0.8064816414325658\n",
      "------------------------------------\n",
      "72\n",
      "0.8107646492073224\n",
      "0.7877079719210157\n",
      "0.808667807354003\n",
      "------------------------------------\n",
      "73\n",
      "0.8223044582639923\n",
      "0.8030634424490158\n",
      "0.8210762413179254\n",
      "------------------------------------\n",
      "74\n",
      "0.8304940001751774\n",
      "0.8142032506022838\n",
      "0.8213716760271539\n",
      "------------------------------------\n",
      "75\n",
      "0.827625470789174\n",
      "0.8087407298588153\n",
      "0.8209635998728885\n",
      "------------------------------------\n",
      "76\n",
      "0.8307786633966892\n",
      "0.813213110821529\n",
      "0.8220290997789484\n",
      "------------------------------------\n",
      "77\n",
      "0.8320924936498204\n",
      "0.8145396005861901\n",
      "0.8249416171308798\n",
      "------------------------------------\n",
      "78\n",
      "0.832245773846019\n",
      "0.8125875139301564\n",
      "0.8267348865144646\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "0.8184067618463694\n",
      "0.7956758957665241\n",
      "0.8198714625490154\n",
      "------------------------------------\n",
      "80\n",
      "0.8252167819917666\n",
      "0.8056562658385295\n",
      "0.8163994916827827\n",
      "------------------------------------\n",
      "81\n",
      "0.8271437330296926\n",
      "0.8069502414108348\n",
      "0.8208989582300469\n",
      "------------------------------------\n",
      "82\n",
      "0.8191512656564772\n",
      "0.8061556327978522\n",
      "0.8105817308999629\n",
      "------------------------------------\n",
      "83\n",
      "0.8174870806691775\n",
      "0.7991521317078513\n",
      "0.8128537217607646\n",
      "------------------------------------\n",
      "84\n",
      "0.8182315844792852\n",
      "0.7949444644807494\n",
      "0.8132978263431442\n",
      "------------------------------------\n",
      "85\n",
      "0.8288298151878777\n",
      "0.809440836052846\n",
      "0.8247287112988518\n",
      "------------------------------------\n",
      "86\n",
      "0.804283086625208\n",
      "0.8011138110879653\n",
      "0.8017301256295345\n",
      "------------------------------------\n",
      "87\n",
      "0.8207935534728913\n",
      "0.8016987605971226\n",
      "0.8149948253343205\n",
      "------------------------------------\n",
      "88\n",
      "0.8257204169221337\n",
      "0.8051645731391971\n",
      "0.8177817027926316\n",
      "------------------------------------\n",
      "89\n",
      "0.8195454147324166\n",
      "0.7972354993014902\n",
      "0.8169107329986752\n",
      "------------------------------------\n",
      "90\n",
      "0.8257423140930192\n",
      "0.8047630510774978\n",
      "0.8207370887341051\n",
      "------------------------------------\n",
      "91\n",
      "0.8241657177892616\n",
      "0.8055050139359685\n",
      "0.8164068069533864\n",
      "------------------------------------\n",
      "92\n",
      "0.8263554348778138\n",
      "0.8102985602373023\n",
      "0.8164906192934959\n",
      "------------------------------------\n",
      "93\n",
      "0.8299246737321538\n",
      "0.8070917734451569\n",
      "0.8262625585554898\n",
      "------------------------------------\n",
      "94\n",
      "0.8260488744854165\n",
      "0.8076969223266888\n",
      "0.8189469250155311\n",
      "------------------------------------\n",
      "95\n",
      "0.7977139353595516\n",
      "0.7795299316563414\n",
      "0.7943289134780596\n",
      "------------------------------------\n",
      "96\n",
      "0.8220635893842515\n",
      "0.80049293306124\n",
      "0.8168543920798208\n",
      "------------------------------------\n",
      "97\n",
      "0.820990628010861\n",
      "0.7956346937935956\n",
      "0.8214594024939031\n",
      "------------------------------------\n",
      "98\n",
      "0.8150345975299991\n",
      "0.7917751061036172\n",
      "0.8130132469064278\n",
      "------------------------------------\n",
      "99\n",
      "0.8277568538144872\n",
      "0.810314513398395\n",
      "0.8184003925501858\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for model_id in range(100):\n",
    "    \n",
    "    str_id = str(model_id)\n",
    "    \n",
    "    model =  load_model('model_1/model_'+ str_id +'.h5') \n",
    "    \n",
    "    all_score = 0\n",
    "    \n",
    "    range_num = int(test_num/test_batch)\n",
    "    \n",
    "    input_lab = []\n",
    "    output_lab = []\n",
    "    \n",
    "    for num_id in range(range_num):\n",
    "        \n",
    "        test_data = all_test_data[num_id*test_batch:test_batch+num_id*test_batch,:,:]\n",
    "        \n",
    "        test_lab = all_test_lab[num_id*test_batch:test_batch+num_id*test_batch,:]\n",
    "    \n",
    "        pre_lab = model.predict(test_data, batch_size=test_batch, verbose=0)\n",
    "             \n",
    "        input_lab.extend(test_lab)\n",
    "        output_lab.extend(pre_lab)\n",
    "\n",
    "    labels_test = np.argmax(input_lab,axis=1)  \n",
    "    labels_pred = np.argmax(output_lab,axis=1)\n",
    "          \n",
    "    Accuracy = accuracy_score(labels_test, labels_pred)\n",
    "    Recall = recall_score(labels_test, labels_pred, average='macro')\n",
    "    #F1_score = f1_score(labels_test, labels_pred, average='macro')\n",
    "    Precision = precision_score(labels_test, labels_pred, average='macro')\n",
    "    \n",
    "    Accuracy_list[model_id] = Accuracy\n",
    "    Recall_list[model_id] = Recall\n",
    "    Precision_list[model_id] = Precision\n",
    "    \n",
    "    print(\"\"+ str(model_id) + \"\")\n",
    "    print(Accuracy)\n",
    "    print(Recall)\n",
    "    print(Precision)\n",
    "    \n",
    "    print(\"------------------------------------\")\n",
    "    \n",
    "    K.clear_session()\n",
    "    tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score:\n",
      "[0.51756, 0.60452, 0.72364, 0.77485, 0.74426, 0.78771, 0.81337, 0.77601, 0.80717, 0.82176, 0.81103, 0.78904, 0.80238, 0.80669, 0.79577, 0.77739, 0.78009, 0.80095, 0.81959, 0.8163, 0.77691, 0.80682, 0.81335, 0.81193, 0.74356, 0.82373, 0.76261, 0.79866, 0.82511, 0.82465, 0.80689, 0.82395, 0.82419, 0.79844, 0.80643, 0.80187, 0.79136, 0.77507, 0.80665, 0.7678, 0.78539, 0.81668, 0.77993, 0.82066, 0.82268, 0.80649, 0.81418, 0.79504, 0.82463, 0.7941, 0.81525, 0.78718, 0.81659, 0.80702, 0.81363, 0.81223, 0.81992, 0.82723, 0.77376, 0.8137, 0.82835, 0.82795, 0.8098, 0.82062, 0.79633, 0.81738, 0.80349, 0.81442, 0.8103, 0.80639, 0.71378, 0.81052, 0.81076, 0.8223, 0.83049, 0.82763, 0.83078, 0.83209, 0.83225, 0.81841, 0.82522, 0.82714, 0.81915, 0.81749, 0.81823, 0.82883, 0.80428, 0.82079, 0.82572, 0.81955, 0.82574, 0.82417, 0.82636, 0.82992, 0.82605, 0.79771, 0.82206, 0.82099, 0.81503, 0.82776]\n",
      "Recall_score:\n",
      "[0.43815, 0.52514, 0.67674, 0.74095, 0.69357, 0.7939, 0.78, 0.74384, 0.81067, 0.79947, 0.7994, 0.76657, 0.79095, 0.80663, 0.74941, 0.79443, 0.76112, 0.80079, 0.80416, 0.79754, 0.74467, 0.80726, 0.78489, 0.80171, 0.76773, 0.80994, 0.72471, 0.79712, 0.81508, 0.8065, 0.79939, 0.79668, 0.79865, 0.76864, 0.80172, 0.77875, 0.76777, 0.74438, 0.7746, 0.77425, 0.75005, 0.80218, 0.75488, 0.80161, 0.81354, 0.79468, 0.79525, 0.77577, 0.80917, 0.76599, 0.79306, 0.75124, 0.79417, 0.78737, 0.79085, 0.78919, 0.80701, 0.80933, 0.76883, 0.78893, 0.81143, 0.81033, 0.79002, 0.79829, 0.76885, 0.79364, 0.78824, 0.78992, 0.79661, 0.79348, 0.75521, 0.79588, 0.78771, 0.80306, 0.8142, 0.80874, 0.81321, 0.81454, 0.81259, 0.79568, 0.80566, 0.80695, 0.80616, 0.79915, 0.79494, 0.80944, 0.80111, 0.8017, 0.80516, 0.79724, 0.80476, 0.80551, 0.8103, 0.80709, 0.8077, 0.77953, 0.80049, 0.79563, 0.79178, 0.81031]\n",
      "Precision_score:\n",
      "[0.42098, 0.53848, 0.711, 0.75482, 0.75857, 0.79508, 0.80544, 0.8035, 0.81781, 0.81976, 0.80113, 0.78779, 0.79272, 0.79858, 0.82124, 0.77633, 0.76231, 0.79139, 0.81355, 0.81604, 0.79019, 0.79475, 0.82568, 0.81763, 0.75261, 0.81238, 0.78137, 0.78982, 0.81708, 0.81928, 0.7999, 0.83246, 0.82456, 0.80376, 0.79307, 0.80425, 0.79429, 0.78531, 0.81074, 0.76728, 0.79541, 0.81005, 0.78253, 0.81586, 0.80984, 0.80317, 0.81026, 0.79353, 0.81931, 0.81359, 0.81214, 0.79434, 0.8121, 0.80232, 0.81003, 0.80802, 0.80959, 0.82171, 0.75077, 0.81431, 0.82042, 0.82107, 0.80328, 0.81842, 0.79773, 0.8185, 0.79134, 0.81675, 0.80154, 0.79105, 0.74212, 0.80648, 0.80867, 0.82108, 0.82137, 0.82096, 0.82203, 0.82494, 0.82673, 0.81987, 0.8164, 0.8209, 0.81058, 0.81285, 0.8133, 0.82473, 0.80173, 0.81499, 0.81778, 0.81691, 0.82074, 0.81641, 0.81649, 0.82626, 0.81895, 0.79433, 0.81685, 0.82146, 0.81301, 0.8184]\n"
     ]
    }
   ],
   "source": [
    "Accuracy_str = \"[\"\n",
    "Recall_str = \"[\"\n",
    "Precision_str = \"[\"\n",
    "\n",
    "for id in range(100):\n",
    "    \n",
    "    Accuracy_num = round(Accuracy_list[id], 5)\n",
    "    Recall_num = round(Recall_list[id], 5)\n",
    "    Precision_num = round(Precision_list[id], 5)\n",
    "\n",
    "    Accuracy_str = Accuracy_str + str(Accuracy_num)\n",
    "    Recall_str = Recall_str + str(Recall_num)\n",
    "    Precision_str = Precision_str + str(Precision_num)\n",
    "    \n",
    "    if id == 99:\n",
    "        Accuracy_str = Accuracy_str + \"]\"\n",
    "        Recall_str = Recall_str + \"]\"\n",
    "        Precision_str = Precision_str + \"]\"\n",
    "    else:\n",
    "        Accuracy_str = Accuracy_str + \", \"\n",
    "        Recall_str = Recall_str + \", \"\n",
    "        Precision_str = Precision_str + \", \"\n",
    "\n",
    "print(\"Accuracy_score:\")\n",
    "print(Accuracy_str)\n",
    "print(\"Recall_score:\")\n",
    "print(Recall_str)\n",
    "print(\"Precision_score:\")\n",
    "print(Precision_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45668,) [0 5 0 ... 8 5 1]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "test_num = 11172\n",
    "test_batch = 133\n",
    "class_num = \"0\"\n",
    "\n",
    "test_num = 3724\n",
    "test_batch = 133\n",
    "class_num = \"1\"\n",
    "\n",
    "test_num = 4704\n",
    "test_batch = 147\n",
    "class_num = \"2\"\n",
    "\n",
    "test_num = 2058\n",
    "test_batch = 147\n",
    "class_num = \"3\"\n",
    "\n",
    "test_num = 1960\n",
    "test_batch = 196\n",
    "class_num = \"4\"\n",
    "\n",
    "test_num = 3920\n",
    "test_batch = 245\n",
    "class_num = \"5\"\n",
    "\n",
    "test_num = 3430\n",
    "test_batch = 343\n",
    "class_num = \"6\"\n",
    "\n",
    "test_num = 3136\n",
    "test_batch = 196\n",
    "class_num = \"7\"\n",
    "\n",
    "test_num = 3234\n",
    "test_batch = 231\n",
    "class_num = \"8\"\n",
    "\n",
    "test_num = 3528\n",
    "test_batch = 147\n",
    "class_num = \"9\"\n",
    "\n",
    "test_num = 3920\n",
    "test_batch = 245\n",
    "class_num = \"10\"\n",
    "\n",
    "test_num = 882\n",
    "test_batch = 147\n",
    "class_num = \"11\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_num = 2058\n",
    "test_batch = 147\n",
    "class_num = \"3\"\n",
    "\n",
    "\n",
    "def get_0_test_data():\n",
    "    \n",
    "    test_data = np.zeros((test_num, 2048, 1), dtype = np.float32)\n",
    "    \n",
    "    test_lab = np.zeros((test_num))\n",
    "    \n",
    "    flag = 0\n",
    "    list = random.sample(range(test_num), test_num)\n",
    "    \n",
    "    for id in list:\n",
    "        \n",
    "        num_id = str(id)\n",
    "        \n",
    "        line_test_data = np.load(\"../../H-S_data/noise_data/\"+cross+\"/\"+snr_str+\"/test_detail/\"+class_num+\"/\" + num_id + \"_test.npy\")\n",
    "        line_test_lab = np.load(\"../../H-S_data/noise_data/\"+cross+\"/\"+snr_str+\"/test_lab_detail/\"+class_num+\"/\" + num_id + \"_lab.npy\")\n",
    "        \n",
    "        line_test_data = normalization_processing(line_test_data)\n",
    "\n",
    "        test_data[flag , :, 0] = line_test_data\n",
    "        \n",
    "        test_lab[flag] = line_test_lab\n",
    "        \n",
    "        flag += 1\n",
    "        \n",
    "    test_hot_lab = to_categorical(test_lab, num_classes=12)\n",
    "    \n",
    "    return test_data, test_hot_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_data, all_test_lab = get_0_test_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2058,)\n",
      "pre-c0: 4, 0.1943634596695821\n",
      "pre-c1: 51, 2.478134110787172\n",
      "pre-c2: 296, 14.382896015549077\n",
      "pre-c3: 1405, 68.27016520894071\n",
      "pre-c4: 1, 0.048590864917395525\n",
      "pre-c5: 44, 2.1379980563654035\n",
      "pre-c6: 27, 1.3119533527696794\n",
      "pre-c7: 72, 3.498542274052478\n",
      "pre-c8: 37, 1.7978620019436347\n",
      "pre-c9: 27, 1.3119533527696794\n",
      "pre-c10: 94, 4.56754130223518\n",
      "pre-c11: 0, 0.0\n",
      "Pre-all: 2058\n",
      "99\n",
      "0.6827016520894071\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model =  load_model('model_1/model_94.h5') \n",
    "\n",
    "all_score = 0\n",
    "\n",
    "range_num = int(test_num/test_batch)\n",
    "\n",
    "input_lab = []\n",
    "output_lab = []\n",
    "\n",
    "for num_id in range(range_num):\n",
    "\n",
    "    test_data = all_test_data[num_id*test_batch:test_batch+num_id*test_batch,:,:]\n",
    "\n",
    "    test_lab = all_test_lab[num_id*test_batch:test_batch+num_id*test_batch,:]\n",
    "\n",
    "    pre_lab = model.predict(test_data, batch_size=test_batch, verbose=0)\n",
    "\n",
    "    input_lab.extend(test_lab)\n",
    "    output_lab.extend(pre_lab)\n",
    "\n",
    "labels_test = np.argmax(input_lab,axis=1)  \n",
    "labels_pred = np.argmax(output_lab,axis=1)\n",
    "\n",
    "\n",
    "print(labels_test.shape)\n",
    "\n",
    "count_0 = np.sum(labels_pred == 0)\n",
    "count_1 = np.sum(labels_pred == 1)\n",
    "count_2 = np.sum(labels_pred == 2)\n",
    "count_3 = np.sum(labels_pred == 3)\n",
    "count_4 = np.sum(labels_pred == 4)\n",
    "count_5 = np.sum(labels_pred == 5)\n",
    "count_6 = np.sum(labels_pred == 6)\n",
    "count_7 = np.sum(labels_pred == 7)\n",
    "count_8 = np.sum(labels_pred == 8)\n",
    "count_9 = np.sum(labels_pred == 9)\n",
    "count_10 = np.sum(labels_pred == 10)\n",
    "count_11 = np.sum(labels_pred == 11)\n",
    "\n",
    "count_all_pre = count_0+count_1+count_2+count_3+count_4+count_5+count_6+count_7+count_8+count_9+count_10+count_11\n",
    "\n",
    "print(\"pre-c0: \"+str(count_0)+\", \"+str(count_0/count_all_pre*100))\n",
    "print(\"pre-c1: \"+str(count_1)+\", \"+str(count_1/count_all_pre*100))\n",
    "print(\"pre-c2: \"+str(count_2)+\", \"+str(count_2/count_all_pre*100))\n",
    "print(\"pre-c3: \"+str(count_3)+\", \"+str(count_3/count_all_pre*100))\n",
    "print(\"pre-c4: \"+str(count_4)+\", \"+str(count_4/count_all_pre*100))\n",
    "print(\"pre-c5: \"+str(count_5)+\", \"+str(count_5/count_all_pre*100))\n",
    "print(\"pre-c6: \"+str(count_6)+\", \"+str(count_6/count_all_pre*100))\n",
    "print(\"pre-c7: \"+str(count_7)+\", \"+str(count_7/count_all_pre*100))\n",
    "print(\"pre-c8: \"+str(count_8)+\", \"+str(count_8/count_all_pre*100))\n",
    "print(\"pre-c9: \"+str(count_9)+\", \"+str(count_9/count_all_pre*100))\n",
    "print(\"pre-c10: \"+str(count_10)+\", \"+str(count_10/count_all_pre*100))\n",
    "print(\"pre-c11: \"+str(count_11)+\", \"+str(count_11/count_all_pre*100))\n",
    "print(\"Pre-all: \"+str(count_all_pre))\n",
    "\n",
    "\n",
    "\n",
    "Accuracy = accuracy_score(labels_test, labels_pred)\n",
    "\n",
    "\n",
    "Accuracy_list[model_id] = Accuracy\n",
    "\n",
    "\n",
    "print(\"\"+ str(model_id) + \"\")\n",
    "print(Accuracy)\n",
    "\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "K.clear_session()\n",
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
